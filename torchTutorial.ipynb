{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self,inDim, hidDim, outDim):\n",
    "        super(TwoLayerNet,self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(inDim,hidDim)\n",
    "        self.linear2 = torch.nn.Linear(hidDim,outDim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = Variable(torch.randn(N, D_in))\n",
    "y = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 670.7916259765625\n",
      "1 618.0191650390625\n",
      "2 572.681640625\n",
      "3 533.1295166015625\n",
      "4 498.1757507324219\n",
      "5 467.1463928222656\n",
      "6 439.26971435546875\n",
      "7 414.2193603515625\n",
      "8 391.2234802246094\n",
      "9 370.0505065917969\n",
      "10 350.2667236328125\n",
      "11 331.6466979980469\n",
      "12 314.1639709472656\n",
      "13 297.62152099609375\n",
      "14 282.0655212402344\n",
      "15 267.3048400878906\n",
      "16 253.2862548828125\n",
      "17 239.92063903808594\n",
      "18 227.1365966796875\n",
      "19 214.9308319091797\n",
      "20 203.28504943847656\n",
      "21 192.2062530517578\n",
      "22 181.63633728027344\n",
      "23 171.54632568359375\n",
      "24 161.92323303222656\n",
      "25 152.73789978027344\n",
      "26 143.9947967529297\n",
      "27 135.6822509765625\n",
      "28 127.78357696533203\n",
      "29 120.29655456542969\n",
      "30 113.20689392089844\n",
      "31 106.48001861572266\n",
      "32 100.13145446777344\n",
      "33 94.12665557861328\n",
      "34 88.46685791015625\n",
      "35 83.14138793945312\n",
      "36 78.13783264160156\n",
      "37 73.442138671875\n",
      "38 69.03752136230469\n",
      "39 64.90475463867188\n",
      "40 61.0234489440918\n",
      "41 57.383724212646484\n",
      "42 53.9764404296875\n",
      "43 50.784767150878906\n",
      "44 47.78591537475586\n",
      "45 44.971736907958984\n",
      "46 42.332366943359375\n",
      "47 39.863155364990234\n",
      "48 37.55674362182617\n",
      "49 35.39708709716797\n",
      "50 33.37028503417969\n",
      "51 31.465688705444336\n",
      "52 29.6761417388916\n",
      "53 27.99734115600586\n",
      "54 26.425765991210938\n",
      "55 24.947153091430664\n",
      "56 23.56047821044922\n",
      "57 22.256078720092773\n",
      "58 21.03119468688965\n",
      "59 19.87825584411621\n",
      "60 18.794578552246094\n",
      "61 17.77374267578125\n",
      "62 16.814485549926758\n",
      "63 15.911111831665039\n",
      "64 15.06047248840332\n",
      "65 14.258797645568848\n",
      "66 13.504413604736328\n",
      "67 12.7940034866333\n",
      "68 12.122748374938965\n",
      "69 11.48942756652832\n",
      "70 10.893240928649902\n",
      "71 10.331730842590332\n",
      "72 9.801614761352539\n",
      "73 9.300857543945312\n",
      "74 8.827573776245117\n",
      "75 8.38016128540039\n",
      "76 7.9576029777526855\n",
      "77 7.559992790222168\n",
      "78 7.184003829956055\n",
      "79 6.828946113586426\n",
      "80 6.492161273956299\n",
      "81 6.17343807220459\n",
      "82 5.871501445770264\n",
      "83 5.585644245147705\n",
      "84 5.315057277679443\n",
      "85 5.0590362548828125\n",
      "86 4.81564998626709\n",
      "87 4.584926128387451\n",
      "88 4.366272449493408\n",
      "89 4.159050941467285\n",
      "90 3.962404251098633\n",
      "91 3.7759435176849365\n",
      "92 3.5991199016571045\n",
      "93 3.431229591369629\n",
      "94 3.2720608711242676\n",
      "95 3.1204957962036133\n",
      "96 2.976651906967163\n",
      "97 2.8398265838623047\n",
      "98 2.7100234031677246\n",
      "99 2.587015390396118\n",
      "100 2.4700489044189453\n",
      "101 2.3585336208343506\n",
      "102 2.2525291442871094\n",
      "103 2.151578187942505\n",
      "104 2.055546760559082\n",
      "105 1.964102029800415\n",
      "106 1.8770374059677124\n",
      "107 1.7939214706420898\n",
      "108 1.7147551774978638\n",
      "109 1.639129877090454\n",
      "110 1.5671051740646362\n",
      "111 1.498475432395935\n",
      "112 1.4331315755844116\n",
      "113 1.370811939239502\n",
      "114 1.3113772869110107\n",
      "115 1.2546586990356445\n",
      "116 1.2005633115768433\n",
      "117 1.1489965915679932\n",
      "118 1.0997800827026367\n",
      "119 1.0528301000595093\n",
      "120 1.0080074071884155\n",
      "121 0.9652168154716492\n",
      "122 0.9243969321250916\n",
      "123 0.8854112029075623\n",
      "124 0.8481428623199463\n",
      "125 0.8125507235527039\n",
      "126 0.7785421013832092\n",
      "127 0.7460843920707703\n",
      "128 0.7151260375976562\n",
      "129 0.6855104565620422\n",
      "130 0.6572154760360718\n",
      "131 0.6301900744438171\n",
      "132 0.6043796539306641\n",
      "133 0.5796820521354675\n",
      "134 0.556037425994873\n",
      "135 0.5334359407424927\n",
      "136 0.5118094086647034\n",
      "137 0.4911261796951294\n",
      "138 0.4713078737258911\n",
      "139 0.45233750343322754\n",
      "140 0.4341699182987213\n",
      "141 0.41677746176719666\n",
      "142 0.40012967586517334\n",
      "143 0.38420984148979187\n",
      "144 0.3689422011375427\n",
      "145 0.3543137013912201\n",
      "146 0.34029000997543335\n",
      "147 0.3268645405769348\n",
      "148 0.3140064477920532\n",
      "149 0.3016637861728668\n",
      "150 0.28983911871910095\n",
      "151 0.27850452065467834\n",
      "152 0.2676331698894501\n",
      "153 0.2572321891784668\n",
      "154 0.24726632237434387\n",
      "155 0.23772957921028137\n",
      "156 0.22856716811656952\n",
      "157 0.21977917850017548\n",
      "158 0.21134795248508453\n",
      "159 0.20326434075832367\n",
      "160 0.19550713896751404\n",
      "161 0.18805573880672455\n",
      "162 0.1809040606021881\n",
      "163 0.17404335737228394\n",
      "164 0.167456716299057\n",
      "165 0.16112175583839417\n",
      "166 0.1550406515598297\n",
      "167 0.1492106169462204\n",
      "168 0.14360332489013672\n",
      "169 0.13821472227573395\n",
      "170 0.13303910195827484\n",
      "171 0.12806934118270874\n",
      "172 0.12329941242933273\n",
      "173 0.11872132122516632\n",
      "174 0.11431600153446198\n",
      "175 0.1100856140255928\n",
      "176 0.106021948158741\n",
      "177 0.10211630165576935\n",
      "178 0.09835971146821976\n",
      "179 0.09474895149469376\n",
      "180 0.0912780612707138\n",
      "181 0.0879378616809845\n",
      "182 0.08472876250743866\n",
      "183 0.0816439613699913\n",
      "184 0.07867428660392761\n",
      "185 0.07581823319196701\n",
      "186 0.07306940108537674\n",
      "187 0.07042665034532547\n",
      "188 0.06788492202758789\n",
      "189 0.06543917953968048\n",
      "190 0.06308513134717941\n",
      "191 0.06081811711192131\n",
      "192 0.05863829329609871\n",
      "193 0.05653972178697586\n",
      "194 0.05452059209346771\n",
      "195 0.052577000111341476\n",
      "196 0.05070445314049721\n",
      "197 0.04890184476971626\n",
      "198 0.047165580093860626\n",
      "199 0.045494936406612396\n",
      "200 0.04388531669974327\n",
      "201 0.04233597218990326\n",
      "202 0.0408436618745327\n",
      "203 0.039405230432748795\n",
      "204 0.03802308812737465\n",
      "205 0.03669147193431854\n",
      "206 0.03541030362248421\n",
      "207 0.03417560085654259\n",
      "208 0.03298351541161537\n",
      "209 0.031835053116083145\n",
      "210 0.03072960488498211\n",
      "211 0.029663516208529472\n",
      "212 0.028636261820793152\n",
      "213 0.027646394446492195\n",
      "214 0.02669232338666916\n",
      "215 0.025773080065846443\n",
      "216 0.024886900559067726\n",
      "217 0.024031847715377808\n",
      "218 0.02320759929716587\n",
      "219 0.022412948310375214\n",
      "220 0.021646056324243546\n",
      "221 0.02090713568031788\n",
      "222 0.020194686949253082\n",
      "223 0.019507020711898804\n",
      "224 0.01884424313902855\n",
      "225 0.01820494420826435\n",
      "226 0.0175880528986454\n",
      "227 0.01699303835630417\n",
      "228 0.016419261693954468\n",
      "229 0.015865588560700417\n",
      "230 0.015331103466451168\n",
      "231 0.014815490692853928\n",
      "232 0.0143177704885602\n",
      "233 0.013837925158441067\n",
      "234 0.01337515190243721\n",
      "235 0.012928045354783535\n",
      "236 0.012496438808739185\n",
      "237 0.012079663574695587\n",
      "238 0.011677268892526627\n",
      "239 0.011288991197943687\n",
      "240 0.010913887061178684\n",
      "241 0.010551982559263706\n",
      "242 0.01020282506942749\n",
      "243 0.009865179657936096\n",
      "244 0.009539352729916573\n",
      "245 0.009224440902471542\n",
      "246 0.008920355699956417\n",
      "247 0.00862683542072773\n",
      "248 0.008343450725078583\n",
      "249 0.008069688454270363\n",
      "250 0.007805202156305313\n",
      "251 0.007549859117716551\n",
      "252 0.007302991114556789\n",
      "253 0.007064460311084986\n",
      "254 0.006833980791270733\n",
      "255 0.006611384451389313\n",
      "256 0.00639619305729866\n",
      "257 0.00618839031085372\n",
      "258 0.005987521260976791\n",
      "259 0.005793561227619648\n",
      "260 0.0056062424555420876\n",
      "261 0.005425103474408388\n",
      "262 0.005249981302767992\n",
      "263 0.005080736242234707\n",
      "264 0.0049170684069395065\n",
      "265 0.004758776165544987\n",
      "266 0.004605915863066912\n",
      "267 0.004458005074411631\n",
      "268 0.004315022844821215\n",
      "269 0.004176886286586523\n",
      "270 0.004043364431709051\n",
      "271 0.003914272412657738\n",
      "272 0.0037892989348620176\n",
      "273 0.003668413497507572\n",
      "274 0.0035515595227479935\n",
      "275 0.003438732121139765\n",
      "276 0.0033296095207333565\n",
      "277 0.0032240264117717743\n",
      "278 0.003121819579973817\n",
      "279 0.0030229235999286175\n",
      "280 0.0029272916726768017\n",
      "281 0.002834932878613472\n",
      "282 0.002745895879343152\n",
      "283 0.0026597101241350174\n",
      "284 0.0025763430166989565\n",
      "285 0.002495735650882125\n",
      "286 0.0024178263265639544\n",
      "287 0.002342396415770054\n",
      "288 0.0022693409118801355\n",
      "289 0.002198669360950589\n",
      "290 0.0021302432287484407\n",
      "291 0.0020640306174755096\n",
      "292 0.0019999395590275526\n",
      "293 0.0019378921715542674\n",
      "294 0.0018779124366119504\n",
      "295 0.0018197556491941214\n",
      "296 0.0017635176191106439\n",
      "297 0.00170905701816082\n",
      "298 0.0016563638346269727\n",
      "299 0.0016053389990702271\n",
      "300 0.001555922906845808\n",
      "301 0.0015080764424055815\n",
      "302 0.001461752224713564\n",
      "303 0.0014168898342177272\n",
      "304 0.0013734736712649465\n",
      "305 0.0013314479729160666\n",
      "306 0.001290695508942008\n",
      "307 0.0012512636603787541\n",
      "308 0.0012130697723478079\n",
      "309 0.0011760698398575187\n",
      "310 0.0011402728268876672\n",
      "311 0.001105563365854323\n",
      "312 0.0010719908168539405\n",
      "313 0.0010394896380603313\n",
      "314 0.0010079562198370695\n",
      "315 0.0009774198988452554\n",
      "316 0.0009478089050389826\n",
      "317 0.0009191444842144847\n",
      "318 0.0008913793135434389\n",
      "319 0.0008644547197036445\n",
      "320 0.0008383824024349451\n",
      "321 0.0008131031063385308\n",
      "322 0.0007886275998316705\n",
      "323 0.0007649133913218975\n",
      "324 0.0007419285248033702\n",
      "325 0.0007196379592642188\n",
      "326 0.0006980461766943336\n",
      "327 0.0006771301850676537\n",
      "328 0.0006568452809005976\n",
      "329 0.0006371946656145155\n",
      "330 0.0006181547068990767\n",
      "331 0.000599704566411674\n",
      "332 0.0005818008212372661\n",
      "333 0.0005644563934765756\n",
      "334 0.0005476443329825997\n",
      "335 0.0005313503206707537\n",
      "336 0.0005155677208676934\n",
      "337 0.0005002414109185338\n",
      "338 0.0004853774153161794\n",
      "339 0.0004709961940534413\n",
      "340 0.00045706669334322214\n",
      "341 0.0004435280861798674\n",
      "342 0.00043041055323556066\n",
      "343 0.00041768912342377007\n",
      "344 0.00040535908192396164\n",
      "345 0.0003933948464691639\n",
      "346 0.00038178282557055354\n",
      "347 0.00037053777487017214\n",
      "348 0.00035963335540145636\n",
      "349 0.00034905309439636767\n",
      "350 0.0003387889009900391\n",
      "351 0.0003288370498921722\n",
      "352 0.0003191842988599092\n",
      "353 0.0003098251181654632\n",
      "354 0.00030074617825448513\n",
      "355 0.0002919345861300826\n",
      "356 0.0002833970356732607\n",
      "357 0.0002751128049567342\n",
      "358 0.00026706737116910517\n",
      "359 0.00025927345268428326\n",
      "360 0.0002517089305911213\n",
      "361 0.00024437555111944675\n",
      "362 0.00023725160281173885\n",
      "363 0.00023034885816741735\n",
      "364 0.00022364572214428335\n",
      "365 0.00021714114700444043\n",
      "366 0.00021083986212033778\n",
      "367 0.000204718773602508\n",
      "368 0.00019879710453096777\n",
      "369 0.00019303754379507154\n",
      "370 0.00018744575208984315\n",
      "371 0.00018201601051259786\n",
      "372 0.00017675459093879908\n",
      "373 0.0001716476253932342\n",
      "374 0.0001666867028689012\n",
      "375 0.00016187875007744879\n",
      "376 0.00015720164810772985\n",
      "377 0.0001526696578366682\n",
      "378 0.00014827393169980496\n",
      "379 0.00014400167856365442\n",
      "380 0.00013986001431476325\n",
      "381 0.00013583867985289544\n",
      "382 0.00013193782069720328\n",
      "383 0.00012813822831958532\n",
      "384 0.00012446234177332371\n",
      "385 0.00012089345545973629\n",
      "386 0.00011742913193302229\n",
      "387 0.00011406502744648606\n",
      "388 0.00011079497926402837\n",
      "389 0.00010762561578303576\n",
      "390 0.00010454760194988921\n",
      "391 0.00010155861673410982\n",
      "392 9.866025357041508e-05\n",
      "393 9.583611245034263e-05\n",
      "394 9.31025788304396e-05\n",
      "395 9.044434409588575e-05\n",
      "396 8.787235128693283e-05\n",
      "397 8.537331450497732e-05\n",
      "398 8.294761937577277e-05\n",
      "399 8.05846430012025e-05\n",
      "400 7.829354581190273e-05\n",
      "401 7.607196312164888e-05\n",
      "402 7.390839164145291e-05\n",
      "403 7.181045657489449e-05\n",
      "404 6.977229350013658e-05\n",
      "405 6.779398972867057e-05\n",
      "406 6.587217649212107e-05\n",
      "407 6.40043435851112e-05\n",
      "408 6.21914878138341e-05\n",
      "409 6.043172106728889e-05\n",
      "410 5.8721434470498934e-05\n",
      "411 5.706087904400192e-05\n",
      "412 5.5451815569540486e-05\n",
      "413 5.388316640164703e-05\n",
      "414 5.236115612206049e-05\n",
      "415 5.088242323836312e-05\n",
      "416 4.9447629862697795e-05\n",
      "417 4.8053450882434845e-05\n",
      "418 4.6699875383637846e-05\n",
      "419 4.538501161732711e-05\n",
      "420 4.41073025285732e-05\n",
      "421 4.286337934900075e-05\n",
      "422 4.165998689131811e-05\n",
      "423 4.048843766213395e-05\n",
      "424 3.934931373805739e-05\n",
      "425 3.8246049371082336e-05\n",
      "426 3.717296203831211e-05\n",
      "427 3.613168519223109e-05\n",
      "428 3.5118071536999196e-05\n",
      "429 3.4136679460061714e-05\n",
      "430 3.317760638310574e-05\n",
      "431 3.224829924874939e-05\n",
      "432 3.1345141906058416e-05\n",
      "433 3.046758138225414e-05\n",
      "434 2.9614029699587263e-05\n",
      "435 2.878763189073652e-05\n",
      "436 2.7982086976408027e-05\n",
      "437 2.720092743402347e-05\n",
      "438 2.6441834052093327e-05\n",
      "439 2.570627475506626e-05\n",
      "440 2.498654430382885e-05\n",
      "441 2.429112464596983e-05\n",
      "442 2.361302904319018e-05\n",
      "443 2.2955422537052073e-05\n",
      "444 2.2314305169857107e-05\n",
      "445 2.1694519091397524e-05\n",
      "446 2.1090787413413636e-05\n",
      "447 2.0503168343566358e-05\n",
      "448 1.993265323108062e-05\n",
      "449 1.9378227079869248e-05\n",
      "450 1.8839546100934967e-05\n",
      "451 1.8317457943339832e-05\n",
      "452 1.7808271877584048e-05\n",
      "453 1.73123917193152e-05\n",
      "454 1.6831378161441535e-05\n",
      "455 1.6366111594834365e-05\n",
      "456 1.5911231457721442e-05\n",
      "457 1.547199826745782e-05\n",
      "458 1.5042887753224932e-05\n",
      "459 1.4626709344156552e-05\n",
      "460 1.42211129059433e-05\n",
      "461 1.3826990652887616e-05\n",
      "462 1.3444833712128457e-05\n",
      "463 1.307223556068493e-05\n",
      "464 1.2710939699900337e-05\n",
      "465 1.2359982974885497e-05\n",
      "466 1.2019177120237146e-05\n",
      "467 1.1686815923894756e-05\n",
      "468 1.1364531019353308e-05\n",
      "469 1.1051031833630987e-05\n",
      "470 1.0745047802629415e-05\n",
      "471 1.044847522280179e-05\n",
      "472 1.0161115824303124e-05\n",
      "473 9.87989733403083e-06\n",
      "474 9.607757419871632e-06\n",
      "475 9.343530109617859e-06\n",
      "476 9.085905730898958e-06\n",
      "477 8.836028428049758e-06\n",
      "478 8.592512131144758e-06\n",
      "479 8.355659701919649e-06\n",
      "480 8.126387911033817e-06\n",
      "481 7.902513061708305e-06\n",
      "482 7.685128366574645e-06\n",
      "483 7.474119684047764e-06\n",
      "484 7.268539320648415e-06\n",
      "485 7.0687920015188865e-06\n",
      "486 6.875180133647518e-06\n",
      "487 6.6866809902421664e-06\n",
      "488 6.5020153670047875e-06\n",
      "489 6.325021786324214e-06\n",
      "490 6.151180059532635e-06\n",
      "491 5.9818648878717795e-06\n",
      "492 5.8182477005175315e-06\n",
      "493 5.658933332597371e-06\n",
      "494 5.5042710300767794e-06\n",
      "495 5.3537751227850094e-06\n",
      "496 5.206972673477139e-06\n",
      "497 5.064949164079735e-06\n",
      "498 4.926255769532872e-06\n",
      "499 4.791096671397099e-06\n"
     ]
    }
   ],
   "source": [
    "for t in range(500):\n",
    "    y_pred = model(x)\n",
    "\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.data[0])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = torch.randn(5,7)\n",
    "vec = vec.view(-1,1)\n",
    "vec.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "Vggmodel = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Need input of dimension 4 and input.size[1] == 3 but got input to be of shape: [1 x 200 x 300 x 3] at /opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/THNN/generic/SpatialConvolutionMM.c:47",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-603e82cab543>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-603e82cab543>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdaptiveMaxPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/torch/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/torch/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 254\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/torch/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     50\u001b[0m     f = ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n\u001b[1;32m     51\u001b[0m                _pair(0), groups, torch.backends.cudnn.benchmark, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Need input of dimension 4 and input.size[1] == 3 but got input to be of shape: [1 x 200 x 300 x 3] at /opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/THNN/generic/SpatialConvolutionMM.c:47"
     ]
    }
   ],
   "source": [
    "class AestheticsNet(nn.Module):\n",
    "            def __init__(self,kw,kh):\n",
    "                super(AestheticsNet, self).__init__()\n",
    "                self.features = nn.Sequential(\n",
    "                    # stop at conv4\n",
    "                    *list(Vggmodel.features.children())[:-1]\n",
    "                )\n",
    "                \n",
    "                self.features.add_module(str(len(self.features)),nn.AdaptiveMaxPool2d((kw,kh)))\n",
    "            def forward(self, x):\n",
    "                x = self.features(x)\n",
    "                \n",
    "                return x\n",
    "\n",
    "model1 = AestheticsNet(4,4)\n",
    "inp = torch.randn(1,,300,3)*255\n",
    "inp = Variable(inp)\n",
    "ft = model1(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python(torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
